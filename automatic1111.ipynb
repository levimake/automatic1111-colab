{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/levimake/automatic1111-colab/blob/main/automatic1111.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OFCYOzNjDX"
      },
      "source": [
        "# [Stable Diffusion WebUI Colab](https://github.com/ddPn08/stable-diffusion-webui-colab) by [ddPn08](https://github.com/ddpn08/)\n",
        "\n",
        "Wiki -> https://github.com/ddPn08/automatic1111-colab/wiki\n",
        "\n",
        "<br />\n",
        "\n",
        "# Troubleshooting (不具合が発生したら)\n",
        "1. First, check the wiki and changelog. (まずは、Wikiと変更ログを確認してください。)\n",
        "  - [Wiki](https://github.com/ddPn08/automatic1111-colab/wiki)\n",
        "  - [CHANGELOG | 変更ログ](#scrollTo=moDR3lrJVsE8)\n",
        "\n",
        "2. If you still can't figure it out, open a Github issue. (それでもわからない場合はGithubのIssueを立ててください。)\n",
        "  - [Github Issue](https://github.com/ddPn08/automatic1111-colab/issues/new)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y4xxtQfuJiWM",
        "outputId": "e64dba3a-d9a6-4bfd-ee6d-d4ca5453a635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 31 17:14:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        533M         10G        1.1M        1.8G         11G\n",
            "Swap:            0B          0B          0B\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi\n",
        "! nvcc -V\n",
        "! free -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE45Pqn_N81E"
      },
      "source": [
        "## 1 - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXkcQu6OEAu"
      },
      "source": [
        "### 1.1 Clone repository\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#11-clone-repository) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#11-リポジトリのクローン)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "yzdbQDudNZ6j",
        "outputId": "32de6f50-7b8f-4a52-e991-ebf7d0b4b2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 12795, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 12795 (delta 0), reused 4 (delta 0), pack-reused 12786\u001b[K\n",
            "Receiving objects: 100% (12795/12795), 25.25 MiB | 14.66 MiB/s, done.\n",
            "Resolving deltas: 100% (8906/8906), done.\n",
            "/content/stable-diffusion-webui\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "repository_url = \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\"  # @param {type: \"string\"}\n",
        "webui_branch = \"master\"  # @param {type: \"string\"}\n",
        "\n",
        "! git clone {repository_url}\n",
        "%cd /content/stable-diffusion-webui\n",
        "! git checkout {webui_branch}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHgDng2c0FX"
      },
      "source": [
        "### 1.2 Setup models\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-EN#12-setup-models) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/1.-Setup-%7C-JP#12-モデルのセットアップ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mls4_48XOrTd",
        "outputId": "e77c36e9-1c17-43ea-b009-f129311626eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--2022-12-31 17:32:10--  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 54.144.222.129, 34.238.87.3, 18.235.116.140, ...\n",
            "Connecting to huggingface.co (huggingface.co)|54.144.222.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556?response-content-disposition=attachment%3B%20filename%3D%22sd-v1-4.ckpt%22&Expires=1672730147&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRjLzM3LzRjMzcyYjRlYmI1N2JiZDAyZTY4NDEzZDQ5NTFhYTMyNmQ0YjNjZmI2ZTYyZGI5ODllNTI5YzZkNGIyNmZiMjEvZmU0ZWZmZjFlMTc0YzYyNzI1NmU0NGVjMjk5MWJhMjc5YjM4MTZlMzY0YjQ5ZjliZTJhYmMwYjNmZjNmODU1Nj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNkLXYxLTQuY2twdCUyMiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY3MjczMDE0N319fV19&Signature=a1QAaVbUYxvcmVdxygBOajotbXETNB~p2YeJ3u8k4u~yv-5rDdP5wIZV2NAK9vjA-nt2NufaJ2W-SOfB9-ayf4cFgHiiFgEwI6rXx9iJ6DYOQl7zYsbflStDRuWrUaStTCfIK5Htjkj0HbDbwJygJJc8vHUMu31fOwtLujitBvyuwJT4BZOh3QIwRBtQPUmAa2v~BUng3weTFiu1eN7haEkxpZUPR09xgPBud1O4NQQC05wVLwX7HVjq0joq53Nj0uD92cyH5rMS4pmP6URlLI9zXmGHhHkQkNfQOBrwwEX0MzpgkSqOCZjvI5wkyk33FXRup9~NT0vJQh5RJCWx3A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-12-31 17:32:11--  https://cdn-lfs.huggingface.co/repos/4c/37/4c372b4ebb57bbd02e68413d4951aa326d4b3cfb6e62db989e529c6d4b26fb21/fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556?response-content-disposition=attachment%3B%20filename%3D%22sd-v1-4.ckpt%22&Expires=1672730147&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzRjLzM3LzRjMzcyYjRlYmI1N2JiZDAyZTY4NDEzZDQ5NTFhYTMyNmQ0YjNjZmI2ZTYyZGI5ODllNTI5YzZkNGIyNmZiMjEvZmU0ZWZmZjFlMTc0YzYyNzI1NmU0NGVjMjk5MWJhMjc5YjM4MTZlMzY0YjQ5ZjliZTJhYmMwYjNmZjNmODU1Nj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPWF0dGFjaG1lbnQlM0IlMjBmaWxlbmFtZSUzRCUyMnNkLXYxLTQuY2twdCUyMiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY3MjczMDE0N319fV19&Signature=a1QAaVbUYxvcmVdxygBOajotbXETNB~p2YeJ3u8k4u~yv-5rDdP5wIZV2NAK9vjA-nt2NufaJ2W-SOfB9-ayf4cFgHiiFgEwI6rXx9iJ6DYOQl7zYsbflStDRuWrUaStTCfIK5Htjkj0HbDbwJygJJc8vHUMu31fOwtLujitBvyuwJT4BZOh3QIwRBtQPUmAa2v~BUng3weTFiu1eN7haEkxpZUPR09xgPBud1O4NQQC05wVLwX7HVjq0joq53Nj0uD92cyH5rMS4pmP6URlLI9zXmGHhHkQkNfQOBrwwEX0MzpgkSqOCZjvI5wkyk33FXRup9~NT0vJQh5RJCWx3A__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.128, 18.155.68.98, 18.155.68.94, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4265380512 (4.0G) [binary/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/AI/automatic1111/models/sd-v1-4.ckpt’\n",
            "\n",
            "              /cont  16%[==>                 ] 680.29M  8.87MB/s    eta 70s    ^C\n",
            "/content/stable-diffusion-webui\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  332M  100  332M    0     0   206M      0  0:00:01  0:00:01 --:--:--  330M\n",
            "curl: Saved to filename 'GFPGANv1.3.pth'\n",
            "models_path: /content/drive/MyDrive/AI/automatic1111/models\n",
            "output_path: /content/drive/MyDrive/AI/automatic1111/outputs\n",
            "config_path: /content/drive/MyDrive/AI/automatic1111/config\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Set up the StableDiffusion model.\n",
        "\n",
        "# @markdown **Model Path Variables**\n",
        "%cd /content/\n",
        "\n",
        "data_dir = \"/content/data\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown **Optional | Download the model if it isn't already in the `{data_dir}/models` folder**\n",
        "download_if_missing = True  # @param {type:\"boolean\"}\n",
        "model_filename = \"\"\n",
        "model_url = \"\"\n",
        "model_config = \"\"\n",
        "# auth_token = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "Model_Version = \"1.4\" #@param [\"1.4\", \"V2.0-512\", \"V2.0-768\"]\n",
        "#@markdown  - Important! Choose the correct version and resolution of the model\n",
        "\n",
        "if Model_Version == \"1.4\":\n",
        "  model_url = \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\"\n",
        "elif Model_Version == \"V2.0-768\":\n",
        "  model_url = \"https://huggingface.co/stabilityai/stable-diffusion-2/resolve/main/768-v-ema.ckpt\"\n",
        "  model_config = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\"\n",
        "elif Model_Version == \"V2.0-512\" :\n",
        "  model_url = \"https://huggingface.co/stabilityai/stable-diffusion-2-base/resolve/main/512-base-ema.ckpt\"\n",
        "  model_config = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml\"\n",
        "\n",
        "\n",
        "# @markdown **Optional | Use Google Drive**\n",
        "mount_google_drive = True  # @param {type:\"boolean\"}\n",
        "force_remount = False  # @param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "mount_success = False\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive\n",
        "\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path, force_remount=force_remount)\n",
        "        data_dir_gdrive = \"/content/drive/MyDrive/AI/automatic1111\"  # @param {type:\"string\"}\n",
        "        data_dir = data_dir_gdrive\n",
        "        mount_success = True\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.pre.sh\"):\n",
        "    ! chmod +x {data_dir}/script.pre.sh\n",
        "    ! {data_dir}/script.pre.sh\n",
        "\n",
        "models_path = f\"{data_dir}/models\"\n",
        "output_path = f\"{data_dir}/outputs\"\n",
        "config_path = f\"{data_dir}/config\"\n",
        "extensions_file_path = f\"{data_dir}/extensions.txt\"\n",
        "\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/Stable-diffusion\", exist_ok=True)\n",
        "\n",
        "for dir in os.listdir(models_path):\n",
        "    if dir == \"embeddings\":\n",
        "        ! rm -Rf stable-diffusion-webui/embeddings && ln -s {models_path}/embeddings stable-diffusion-webui/models/embeddings\n",
        "    else:\n",
        "        ! rm -Rf stable-diffusion-webui/models/{dir} && ln -s {models_path}/{dir} stable-diffusion-webui/models/{dir}\n",
        "\n",
        "! rm -f stable-diffusion-webui/outputs && ln -s {data_dir}/outputs stable-diffusion-webui/outputs\n",
        "! rm -f stable-diffusion-webui/config.json && ln -s {config_path}/config.json stable-diffusion-webui/config.json\n",
        "! rm -f stable-diffusion-webui/ui-config.json && ln -s {config_path}/ui-config.json stable-diffusion-webui/ui-config.json\n",
        "\n",
        "if download_if_missing:\n",
        "    if not model_filename:\n",
        "        model_filename = model_url.split(\"/\")[-1]\n",
        "        model_configname = model_filename.split(\".\")[0] + \".yaml\"\n",
        "    if not mount_success:\n",
        "        print(\"Downloading model to \" + models_path + \" due to gdrive mount error\")\n",
        "    elif not model_filename or not os.path.exists(models_path + \"/\" + model_filename):\n",
        "        ! wget {model_url} -O {models_path}/{model_filename}\n",
        "        if Model_Version != \"1.4\":\n",
        "          ! wget {model_config} -O {models_path}/{model_configname}\n",
        "    else:\n",
        "        print(\"Model already downloaded, moving to next step\")\n",
        "\n",
        "%cd /content/stable-diffusion-webui\n",
        "! curl -LOJ https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "\n",
        "print(f\"models_path: {models_path}\")\n",
        "print(f\"output_path: {output_path}\")\n",
        "print(f\"config_path: {config_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JkrcrPBza-M"
      },
      "source": [
        "## 2 - Advanced - Launch preferences\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-EN#2-launch-preferences) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/2.-Launch-preferences-%7C-JP#2-起動設定)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goUvyTZ4zd4l"
      },
      "outputs": [],
      "source": [
        "# @markdown &nbsp;\n",
        "# @markdown ## Command line arguments\n",
        "\n",
        "import os\n",
        "\n",
        "no_half = False  # @param {type:\"boolean\"}\n",
        "no_half_vae = False # @param {type:\"boolean\"}\n",
        "allow_code = False # @param {type:\"boolean\"}\n",
        "no_progressbar_hiding = False  # @param {type:\"boolean\"}\n",
        "medvram = False  # @param {type:\"boolean\"}\n",
        "lowvram = True  # @param {type:\"boolean\"}\n",
        "deepdanbooru = True # @param {type:\"boolean\"}\n",
        "xformers = True  # @param {type:\"boolean\"}\n",
        "disable_opt_split_attention = False  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown &nbsp;\n",
        "custom_arguments = \"\" # @param {type:\"string\"}\n",
        "\n",
        "run_string_with_variables = {\n",
        "    \"--no-half\": f\"{no_half}\",\n",
        "    \"--no-half-vae\": f\"{no_half_vae}\",\n",
        "    \"--allow-code\": f\"{allow_code}\",\n",
        "    \"--no-progressbar-hiding\": f\"{no_progressbar_hiding}\",\n",
        "    \"--medvram\": f\"{medvram}\",\n",
        "    \"--lowvram\": f\"{lowvram}\",\n",
        "    \"--deepdanbooru\": f\"{deepdanbooru}\",\n",
        "    \"--xformers\": f\"{xformers}\",\n",
        "    \"--disable-opt-split-attention\": f\"{disable_opt_split_attention}\",\n",
        "}\n",
        "\n",
        "advanced_options = {k for (k, v) in run_string_with_variables.items() if v == \"True\"}\n",
        "# @markdown &nbsp;\n",
        "# @markdown ## Enable password authentication (Prevent other users from using the WebUI)\n",
        "\n",
        "# @markdown &nbsp;\n",
        "use_gradio_auth = False # @param {type:\"boolean\"}\n",
        "gradio_auth_username = \"username\" # @param {type:\"string\"}\n",
        "gradio_auth_password = \"password\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown &nbsp;\n",
        "# @markdown # Advanced | Network preferences\n",
        "\n",
        "# @markdown &nbsp;\n",
        "# @markdown ## Optional | Ngrok Tunnel\n",
        "# @markdown Get token from [here](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
        "use_ngrok = False  # @param {type: \"boolean\"}\n",
        "load_token_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "ngrok_auth_token = \"\"  # @param {type: \"string\"}\n",
        "ngrok_region = \"auto\"  # @param [\"auto\", \"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/ngrok.txt\") and use_ngrok:\n",
        "    with open(f\"{data_dir}/ngrok.txt\", mode=\"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        if not ngrok_auth_token and len(lines) > 0:\n",
        "            ngrok_auth_token = lines[0].strip()\n",
        "        if ngrok_region == \"auto\" and len(lines) > 1:\n",
        "            ngrok_region = lines[1].strip()\n",
        "\n",
        "with open(f\"{data_dir}/ngrok.txt\", mode=\"w\") as f:\n",
        "    f.write(f\"{ngrok_auth_token}\\n{ngrok_region}\")\n",
        "\n",
        "if not ngrok_region or ngrok_region == \"auto\":\n",
        "    ngrok_region = \"us\"\n",
        "\n",
        "# @markdown &nbsp;\n",
        "# @markdown ## Optional | Tailscale\n",
        "# @markdown Get auth key from [here](https://login.tailscale.com/admin/settings/keys)\n",
        "use_tailscale = False  # @param {type: \"boolean\"}\n",
        "tailscale_auth_key = \"\"  # @param {type: \"string\"}\n",
        "\n",
        "# @markdown ## Extensions\n",
        "load_extensions_from_gdrive = True  # @param {type:\"boolean\"}\n",
        "extensions = \"https://github.com/yfszzx/stable-diffusion-webui-images-browser, https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"  # @param {type:\"string\"}\n",
        "extensions = list(map(str.strip, extensions.split(',')))\n",
        "\n",
        "if load_extensions_from_gdrive and extensions_file_path:\n",
        "    if os.path.exists(extensions_file_path):\n",
        "        with open(extensions_file_path, mode=\"r\") as f:\n",
        "            for s in f:\n",
        "                url = s.strip()\n",
        "                if url not in extensions:\n",
        "                    extensions.append(url)\n",
        "    with open(extensions_file_path, mode=\"w+\") as f:\n",
        "        f.write(\"\\n\".join(extensions))\n",
        "\n",
        "vars = \" \".join(advanced_options)\n",
        "if not use_ngrok:\n",
        "    vars += \" --share\"\n",
        "elif ngrok_auth_token and ngrok_region:\n",
        "    vars += f\" --ngrok {ngrok_auth_token} --ngrok-region {ngrok_region}\"\n",
        "\n",
        "if use_gradio_auth:\n",
        "    vars += f\" --gradio-auth {gradio_auth_username}:{gradio_auth_password}\"\n",
        "\n",
        "os.environ['COMMANDLINE_ARGS'] = f\"{vars} {custom_arguments}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htQtwGXHTaob"
      },
      "source": [
        "## 3 - Launch WebUI\n",
        "[Wiki / English](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-EN#set-up-the-environment) - [Wiki / 日本語](https://github.com/ddPn08/automatic1111-colab/wiki/3.-Run-%7C-JP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao2t5h5qG9HD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @markdown ## Setup environment\n",
        "# @markdown This may take up to 10 minutes\n",
        "\n",
        "store_env_gdrive = False # @param{type:\"boolean\"}\n",
        "force_reinstall_environmemt = False # @param{type:\"boolean\"}\n",
        "gdrive_env_directory = f\"{data_dir}/conda-env\"\n",
        "gdrive_env_file = f\"{gdrive_env_directory}/env.tar.zst\"\n",
        "\n",
        "%cd /content/stable-diffusion-webui/extensions\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "for extension in extensions:\n",
        "    ! git clone {extension}\n",
        "    extension_name = extension.split(\"/\")[-1]\n",
        "    ! cd {extension_name} && git fetch\n",
        "\n",
        "%cd /content\n",
        "\n",
        "! curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/bionic.gpg | sudo apt-key add -\n",
        "! curl -fsSL https://pkgs.tailscale.com/stable/ubuntu/bionic.list | sudo tee /etc/apt/sources.list.d/tailscale.list\n",
        "\n",
        "! apt update\n",
        "! apt upgrade -y\n",
        "! apt install tailscale zstd -y\n",
        "\n",
        "! rm -rf /tmp/tailscaled && mkdir -p /tmp/tailscaled && chown irc.irc /tmp/tailscaled\n",
        "! rm -rf /var/run/tailscale && mkdir -p /var/run/tailscale && chown irc.irc /var/run/tailscale\n",
        "! cp /var/lib/tailscaled/tailscaled.state /tmp/tailscaled/tailscaled.state && chown irc.irc /tmp/tailscaled/tailscaled.state\n",
        "! nohup sudo -u irc tailscaled --tun=userspace-networking --socks5-server=localhost:1055 --state=/tmp/tailscaled/tailscaled.state --socket=/var/run/tailscale/tailscaled.sock --port 41641 &\n",
        "if use_tailscale:\n",
        "    ! until tailscale up --authkey {tailscale_auth_key}; do sleep 1; done\n",
        "\n",
        "if not os.path.exists(\"/usr/local/bin/conda\"):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "    ! rm Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "\n",
        "if os.path.exists(gdrive_env_file) and not os.path.exists(\"/usr/local/envs/automatic\") and not force_reinstall_environmemt:\n",
        "    os.makedirs(\"/usr/local/envs/automatic\", exist_ok=True)\n",
        "    ! zstd -dc {gdrive_env_file} | tar -xf - -C /usr/local/envs/automatic\n",
        "    ! cd stable-diffusion-webui && conda env update -n automatic -f ./environment-wsl2.yaml\n",
        "else:\n",
        "    ! cd stable-diffusion-webui && conda env create -f ./environment-wsl2.yaml\n",
        "\n",
        "install_script = \"\"\"#!/bin/bash\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "cd stable-diffusion-webui\n",
        "conda activate automatic\n",
        "conda install -y xformers -c xformers/label/dev\n",
        "python3 -m pip install --upgrade tensorrt triton\n",
        "python -c 'from launch import prepare_environment; prepare_environment()'\"\"\"\n",
        "! {install_script}\n",
        "\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = f\"{os.environ['LD_LIBRARY_PATH']}:/usr/local/envs/automatic/lib\"\n",
        "\n",
        "if os.path.exists(f\"{data_dir}/script.post.sh\"):\n",
        "    ! chmod +x {data_dir}/script.post.sh\n",
        "    ! {data_dir}/script.post.sh\n",
        "\n",
        "if store_env_gdrive and mount_google_drive and mount_success:\n",
        "    import threading\n",
        "    def pack():\n",
        "        os.makedirs(gdrive_env_directory, exist_ok=True)\n",
        "        ! tar -C /usr/local/envs/automatic -cf - . | zstd > /content/tmp.tar.zst\n",
        "        ! mv /content/tmp.tar.zst {gdrive_env_file}\n",
        "        print(\"Finish storing environment.\")\n",
        "    threading.Thread(target=pack).start()\n",
        "    print(\"Started storing the conda environment in a separate thread. This will take approximately 2 minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y4ebYsPqTrGb"
      },
      "outputs": [],
      "source": [
        "# @markdown # Run script\n",
        "# @markdown keep in mind that this script is set to run for ever.\n",
        "# @markdown > ※注意 このスクリプトは永久に実行されます。\n",
        "\n",
        "# @markdown &nbsp;\n",
        "\n",
        "# @markdown ### Important - click the public URL to launch WebUI in another tab\n",
        "# @markdown > ### 重要 - 公開URLをクリックしてWebUIを起動してください\n",
        "\n",
        "# @markdown ![](https://user-images.githubusercontent.com/71378929/189563599-6df78bcf-133b-41e8-a55d-8ca3783cd933.png)\n",
        "\n",
        "%cd /content/stable-diffusion-webui/\n",
        "! git pull\n",
        "\n",
        "run_script = \"\"\"#!/bin/sh\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate automatic\n",
        "python launch.py\"\"\"\n",
        "! {run_script}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moDR3lrJVsE8"
      },
      "source": [
        "# CHANGELOG (変更ログ)\n",
        "\n",
        "## 2022/12/18 BREAKING CHANGE\n",
        "モデル等のディレクトリの構造を変更しました。くわしくは[こちら](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-JP)  \n",
        "Changed the directory structure of models etc. For details [here](https://github.com/ddPn08/automatic1111-colab/wiki/Data-directory-%7C-EN)  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "automatic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 | packaged by conda-forge | (main, Oct  7 2022, 20:14:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "27f3fb6862b547830c34fbd0390b87507e21782526fd5ca25cfe7dc4f2b0fdae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}